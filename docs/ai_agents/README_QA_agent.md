WdroÅ¼enie Agenta Wiedzy (QA / Chat z Dokumentem)
Data: 19.01.2026 Status: ZakoÅ„czono pomyÅ›lnie âœ…

1. Cel WdroÅ¼enia
Celem dzisiejszych prac byÅ‚o uruchomienie funkcjonalnoÅ›ci RAG (Retrieval-Augmented Generation) w interfejsie uÅ¼ytkownika. UmoÅ¼liwia ona prowadzenie interaktywnego czatu z wybranym dokumentem, gdzie AI odpowiada na pytania wyÅ‚Ä…cznie na podstawie treÅ›ci tego dokumentu (z podaniem ÅºrÃ³deÅ‚).

2. Architektura RozwiÄ…zania
System dziaÅ‚a w modelu "Hybrydowym":

Backend (Django + pgvector): Odpowiada za logikÄ™ wyszukiwania semantycznego (szukanie fragmentÃ³w tekstu pasujÄ…cych do pytania).

Frontend (React): Odpowiada za interfejs czatu (okno modalne) i komunikacjÄ™ z API.

ğŸ¢ Backend (Zmiany)
Nowy Endpoint: POST /api/agents/ask/<doc_id>/

Przyjmuje JSON: {"question": "..."}.

Zwraca JSON: {"answer": "...", "sources": ["...", "..."]}.

Logika (AskDocumentView w views.py):

Krok 1: Zamiana pytania uÅ¼ytkownika na wektor (Embedding) przy uÅ¼yciu OpenAI (text-embedding-3-small).

Krok 2: Przeszukanie bazy danych (DocumentChunk) w celu znalezienia 5 fragmentÃ³w o najmniejszym dystansie euklidesowym (L2) od wektora pytania.

Krok 3: Sklejenie fragmentÃ³w w "Kontekst".

Krok 4: WysÅ‚anie do GPT-4o-mini promptu systemowego: "Odpowiadaj tylko na podstawie poniÅ¼szego kontekstu".

Routing (urls.py):

Zarejestrowano nowÄ… Å›cieÅ¼kÄ™ dla widoku QA.

ğŸ–¥ï¸ Frontend (Zmiany)
Nowy Komponent: DocumentChatModal.tsx

NiezaleÅ¼ne okno dialogowe (Modal) wyÅ›wietlane nad aplikacjÄ….

ObsÅ‚uguje historiÄ™ czatu (User vs Assistant).

WyÅ›wietla ÅºrÃ³dÅ‚a (cytaty), na ktÃ³rych oparÅ‚o siÄ™ AI, co zwiÄ™ksza wiarygodnoÅ›Ä‡ odpowiedzi.

Wykorzystuje "czysty" React (useState, useRef) bez zewnÄ™trznych bibliotek czatowych.

Integracja w AISummary.tsx

Dodano przycisk "Zapytaj" na kafelkach dokumentÃ³w (obok przycisku "Streszczaj").

KlikniÄ™cie otwiera modal w kontekÅ›cie konkretnego dokumentu.

3. PrzepÅ‚yw Danych (Data Flow)
Kiedy uÅ¼ytkownik zadaje pytanie:

Frontend wysyÅ‚a tekst pytania do API.

Backend nie czyta caÅ‚ego pliku (co byÅ‚oby wolne i drogie).

Backend przeszukuje tabelÄ™ DocumentChunk (gdzie wczeÅ›niej pociÄ™liÅ›my plik na kawaÅ‚ki po ~1000 znakÃ³w).

Znalezione "chunki" sÄ… wstrzykiwane do promptu GPT.

GPT generuje odpowiedÅº.

UÅ¼ytkownik otrzymuje odpowiedÅº w uÅ‚amku sekundy (dziÄ™ki szybkiemu wyszukiwaniu wektorowemu).

4. Wymagania WstÄ™pne (WaÅ¼ne!)
Aby czat dziaÅ‚aÅ‚ dla danego dokumentu, musi on zostaÄ‡ wczeÅ›niej zindeksowany.

Proces indeksowania (ciÄ™cie na chunki + embedding) uruchamia siÄ™ endpointem /api/agents/index/<id>/.

JeÅ›li dokument nie jest zindeksowany, Czat zwrÃ³ci komunikat o bÅ‚Ä™dzie.

5. Pliki Zmodyfikowane/Dodane
backend/ai_agents/views.py (Logika RAG)

backend/ai_agents/urls.py (Routing)

frontend/src/components/DocumentChatModal.tsx (Nowy komponent UI)

frontend/src/pages/AISummary.tsx (Integracja przycisku)